{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8257331c-f8e9-465b-8ee2-75037e10d359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/Desktop/Dr. Sohiel/FIXUS-App/Notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d94024d1-020e-453d-aaaa-1a1ff1c859db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/Desktop/Dr. Sohiel\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47603c00-a1c6-4600-8437-93a86cb6b742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIXUS-App  Images  Images.zip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "170565f0-f16b-4131-bde1-4cdb4f19dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8e991493-ace5-4d2d-86b6-70747ebdd0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1920 images belonging to 2 classes.\n",
      "Found 479 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_data = datagen.flow_from_directory(\"Images/\",class_mode='binary',\n",
    "                                         color_mode='grayscale',\n",
    "                                         target_size=(256, 256),\n",
    "                                         subset='training')\n",
    "test_data = datagen.flow_from_directory(\"Images/\",class_mode='binary',\n",
    "                                         color_mode='grayscale',\n",
    "                                         target_size=(256, 256),\n",
    "                                         subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a77971c7-2474-49b8-ba8c-0a288b9a93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32,activation='relu'))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "af93106a-a9dd-43e1-b4c3-8ffd9ef6dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "82b554bd-e617-4c2a-8e8c-ecab89124436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 254, 254, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 127, 127, 32)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 62, 62, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 230400)            0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                7372832   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7428609 (28.34 MB)\n",
      "Trainable params: 7428609 (28.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "598aaabc-d9ec-44f6-addf-22e295f4a18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60/60 [==============================] - 124s 2s/step - loss: 0.3189 - accuracy: 0.8479\n",
      "Epoch 2/4\n",
      "60/60 [==============================] - 111s 2s/step - loss: 0.0719 - accuracy: 0.9760\n",
      "Epoch 3/4\n",
      "60/60 [==============================] - 113s 2s/step - loss: 0.0401 - accuracy: 0.9870\n",
      "Epoch 4/4\n",
      "60/60 [==============================] - 112s 2s/step - loss: 0.0329 - accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ad658f01-b34a-450d-8770-ab1beb802035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 11s 628ms/step - loss: 0.0716 - accuracy: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07160575687885284, 0.9791231751441956]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "72bea731-8137-4fff-acba-6cd22c0ccae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/env/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('FIXUS-App/Models/foot-leg-classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f4979e5e-cab7-4106-94ad-2b8a1f4e1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.load_model('FIXUS-App/Models/foot-leg-classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2ea2bd01-1fa5-4639-93c9-100d2e5ef29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 11s 609ms/step - loss: 0.0716 - accuracy: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07160575687885284, 0.9791231751441956]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59041a-9c41-49a7-ab8f-cd61aaf8270d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
